{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_len = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_outliers(data, threshold=73):\n",
    "    titles = {i: i.lower() for i in data.columns}\n",
    "    return (data.rename(columns=titles).query('expected <= @threshold').copy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seq_pad(data, size, steps=seq_len):\n",
    "    arr = []\n",
    "    for i in data:\n",
    "        _ = i.copy()\n",
    "        _.resize(steps, size)\n",
    "        arr.append(_)\n",
    "    arr = np.array(arr)\n",
    "    return arr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Loading"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "training - 20 days of each month\n",
    "test - remaining days\n",
    "Both sets are independent\n",
    "Calendar time and location information omitted:\n",
    "    impossible to construct a local validation holdout subset independent from the rest of the training set\n",
    "    no way to ensure that any two gauge readings are not correlated in time/space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "#zf1 = zipfile.ZipFile('../../train.zip')\n",
    "#zf2 = zipfile.ZipFile('../../test.zip')\n",
    "#train = pd.read_csv(zf1.open(zipfile.ZipFile.namelist(zf1)[0]))\n",
    "#test = pd.read_csv(zf2.open(zipfile.ZipFile.namelist(zf2)[0]))\n",
    "train = pd.read_csv('../../train.csv', nrows=10000).pipe(remove_outliers)\n",
    "test = pd.read_csv('../../test.csv', nrows=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>minutes_past</th>\n",
       "      <th>radardist_km</th>\n",
       "      <th>ref</th>\n",
       "      <th>ref_5x5_10th</th>\n",
       "      <th>ref_5x5_50th</th>\n",
       "      <th>ref_5x5_90th</th>\n",
       "      <th>refcomposite</th>\n",
       "      <th>refcomposite_5x5_10th</th>\n",
       "      <th>refcomposite_5x5_50th</th>\n",
       "      <th>...</th>\n",
       "      <th>rhohv_5x5_90th</th>\n",
       "      <th>zdr</th>\n",
       "      <th>zdr_5x5_10th</th>\n",
       "      <th>zdr_5x5_50th</th>\n",
       "      <th>zdr_5x5_90th</th>\n",
       "      <th>kdp</th>\n",
       "      <th>kdp_5x5_10th</th>\n",
       "      <th>kdp_5x5_50th</th>\n",
       "      <th>kdp_5x5_90th</th>\n",
       "      <th>expected</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>10.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>10.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "      <td>10.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>35</td>\n",
       "      <td>10.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>45</td>\n",
       "      <td>10.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.254</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  minutes_past  radardist_km  ref  ref_5x5_10th  ref_5x5_50th  \\\n",
       "0   1             3          10.0  NaN           NaN           NaN   \n",
       "1   1            16          10.0  NaN           NaN           NaN   \n",
       "2   1            25          10.0  NaN           NaN           NaN   \n",
       "3   1            35          10.0  NaN           NaN           NaN   \n",
       "4   1            45          10.0  NaN           NaN           NaN   \n",
       "\n",
       "   ref_5x5_90th  refcomposite  refcomposite_5x5_10th  refcomposite_5x5_50th  \\\n",
       "0           NaN           NaN                    NaN                    NaN   \n",
       "1           NaN           NaN                    NaN                    NaN   \n",
       "2           NaN           NaN                    NaN                    NaN   \n",
       "3           NaN           NaN                    NaN                    NaN   \n",
       "4           NaN           NaN                    NaN                    NaN   \n",
       "\n",
       "   ...  rhohv_5x5_90th  zdr  zdr_5x5_10th  zdr_5x5_50th  zdr_5x5_90th  kdp  \\\n",
       "0  ...             NaN  NaN           NaN           NaN           NaN  NaN   \n",
       "1  ...             NaN  NaN           NaN           NaN           NaN  NaN   \n",
       "2  ...             NaN  NaN           NaN           NaN           NaN  NaN   \n",
       "3  ...             NaN  NaN           NaN           NaN           NaN  NaN   \n",
       "4  ...             NaN  NaN           NaN           NaN           NaN  NaN   \n",
       "\n",
       "   kdp_5x5_10th  kdp_5x5_50th  kdp_5x5_90th  expected  \n",
       "0           NaN           NaN           NaN     0.254  \n",
       "1           NaN           NaN           NaN     0.254  \n",
       "2           NaN           NaN           NaN     0.254  \n",
       "3           NaN           NaN           NaN     0.254  \n",
       "4           NaN           NaN           NaN     0.254  \n",
       "\n",
       "[5 rows x 24 columns]"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_t = train.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5-layer deep stacked Bi-RNN, 64-256 hidden units, dense after each hidden stack, \n",
    "last layer at each time position vector is fed into a dense layer with 1 output and ReLU. Take mean of the predictions from the entire top layer\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing\n",
    "exclude the rain gauges with readings above 70mm.\n",
    "replace missing radar feature values with zero\n",
    "each timestamp as a component in the feature vector, sequential nature of the input is preserved"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_t['count_id'] = train_t.groupby('Id')['Id'].transform('count')\n",
    "#train_t['count_None_Ref'] = train_t[~np.isnan(train_t.Ref)].transform('count')\n",
    "train_nones = train_t[~np.isnan(train_t['ref'])]['id'].unique()\n",
    "train_full = train_t['id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_cleaned = train[np.in1d(train_full, train_nones)].fillna(0.0).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "ids = train_cleaned['id'].unique()\n",
    "train_ids = np.random.choice(ids,\n",
    "                               size=np.ceil(len(ids) * (9/10.)).astype(int),\n",
    "                               replace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = train.loc[train['id'].isin(train_ids)]\n",
    "test_data = train.loc[~train['id'].isin(train_ids)]\n",
    "#[train.columns != 'expected']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>minutes_past</th>\n",
       "      <th>radardist_km</th>\n",
       "      <th>ref</th>\n",
       "      <th>ref_5x5_10th</th>\n",
       "      <th>ref_5x5_50th</th>\n",
       "      <th>ref_5x5_90th</th>\n",
       "      <th>refcomposite</th>\n",
       "      <th>refcomposite_5x5_10th</th>\n",
       "      <th>refcomposite_5x5_50th</th>\n",
       "      <th>...</th>\n",
       "      <th>rhohv_5x5_90th</th>\n",
       "      <th>zdr</th>\n",
       "      <th>zdr_5x5_10th</th>\n",
       "      <th>zdr_5x5_50th</th>\n",
       "      <th>zdr_5x5_90th</th>\n",
       "      <th>kdp</th>\n",
       "      <th>kdp_5x5_10th</th>\n",
       "      <th>kdp_5x5_50th</th>\n",
       "      <th>kdp_5x5_90th</th>\n",
       "      <th>expected</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>18.5</td>\n",
       "      <td>16.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>23.5</td>\n",
       "      <td>24.5</td>\n",
       "      <td>22.0</td>\n",
       "      <td>23.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0.998333</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.4375</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.064002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>9.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>25.5</td>\n",
       "      <td>22.5</td>\n",
       "      <td>25.5</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.064002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>9.0</td>\n",
       "      <td>35.5</td>\n",
       "      <td>24.5</td>\n",
       "      <td>30.5</td>\n",
       "      <td>35.5</td>\n",
       "      <td>35.5</td>\n",
       "      <td>25.5</td>\n",
       "      <td>31.5</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.064002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>4</td>\n",
       "      <td>14</td>\n",
       "      <td>9.0</td>\n",
       "      <td>16.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>19.0</td>\n",
       "      <td>34.5</td>\n",
       "      <td>23.5</td>\n",
       "      <td>16.5</td>\n",
       "      <td>23.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.064002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>4</td>\n",
       "      <td>19</td>\n",
       "      <td>9.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>20.5</td>\n",
       "      <td>13.5</td>\n",
       "      <td>18.5</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.064002</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    id  minutes_past  radardist_km   ref  ref_5x5_10th  ref_5x5_50th  \\\n",
       "30   4             0           9.0  18.5          16.0          19.0   \n",
       "31   4             5           9.0  22.0          14.0          21.0   \n",
       "32   4             9           9.0  35.5          24.5          30.5   \n",
       "33   4            14           9.0  16.5           NaN          19.0   \n",
       "34   4            19           9.0  16.0           NaN          11.0   \n",
       "\n",
       "    ref_5x5_90th  refcomposite  refcomposite_5x5_10th  refcomposite_5x5_50th  \\\n",
       "30          23.5          24.5                   22.0                   23.5   \n",
       "31          30.0          25.5                   22.5                   25.5   \n",
       "32          35.5          35.5                   25.5                   31.5   \n",
       "33          34.5          23.5                   16.5                   23.0   \n",
       "34          18.0          20.5                   13.5                   18.5   \n",
       "\n",
       "    ...  rhohv_5x5_90th  zdr  zdr_5x5_10th  zdr_5x5_50th  zdr_5x5_90th  kdp  \\\n",
       "30  ...        0.998333  NaN           NaN           NaN        1.4375  NaN   \n",
       "31  ...             NaN  NaN           NaN           NaN           NaN  NaN   \n",
       "32  ...             NaN  NaN           NaN           NaN           NaN  NaN   \n",
       "33  ...             NaN  NaN           NaN           NaN           NaN  NaN   \n",
       "34  ...             NaN  NaN           NaN           NaN           NaN  NaN   \n",
       "\n",
       "    kdp_5x5_10th  kdp_5x5_50th  kdp_5x5_90th  expected  \n",
       "30           NaN           NaN           NaN  4.064002  \n",
       "31           NaN           NaN           NaN  4.064002  \n",
       "32           NaN           NaN           NaN  4.064002  \n",
       "33           NaN           NaN           NaN  4.064002  \n",
       "34           NaN           NaN           NaN  4.064002  \n",
       "\n",
       "[5 rows x 24 columns]"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = train_data.groupby('id')['expected'].last().values\n",
    "\n",
    "y_test = test_data.groupby('id')['expected'].last().values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5702, 24)"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(484,)"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_arr = y_train.astype('float')\n",
    "test_data_arr = y_test.astype('float')\n",
    "\n",
    "seq_lens_train = train_data.groupby('id').size().values\n",
    "seq_lens_test = test_data.groupby('id').size().values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(484,)"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data_arr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "tuple index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-110-b92e592c48a9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mn_in\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_data_arr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mn_out\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mseq_len\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mseq_lens_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseq_lens_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mneurons\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m256\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: tuple index out of range"
     ]
    }
   ],
   "source": [
    "n_in = train_data_arr.shape[1]\n",
    "n_out = 1\n",
    "seq_len = max([seq_lens_train.max(), seq_lens_test.max()])\n",
    "neurons = [128, 256]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = seq_pad(test_data_arr, n_in, seq_len)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = tf.placeholder(dtype=tf.float32, shape=[None, seq_len , n_in])\n",
    "y = tf.placeholder(tf.float32, [None])\n",
    "seq_length = tf.placeholder(dtype=tf.int16, shape=[None])\n",
    "\n",
    "with tf.variable_scope('rnn', initializer=tf.contrib.layers.variance_scaling_initializer()):\n",
    "    rnn_cell_1 = tf.contrib.rnn.LSTMCell(num_units=neurons[0])\n",
    "    rnn_cell_2 = tf.contrib.rnn.LSTMCell(num_units=neurons[1])\n",
    "    multi_layer_cell = tf.contrib.rnn.MultiRNNCell([rnn_cell_1, rnn_cell_2])\n",
    "    outputs, states = tf.nn.dynamic_rnn(multi_layer_cell, X, dtype=tf.float32,\n",
    "                                        sequence_length=seq_length)\n",
    "    drop = tf.layers.dropout(inputs=states[1], rate=0.4)\n",
    "    y_pred = tf.layers.dense(drop, n_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.05\n",
    "\n",
    "error = (y-y_pred)\n",
    "loss = tf.reduce_mean(tf.square(error), name=\"loss\")\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate)\n",
    "training_op = optimizer.minimize(loss)\n",
    "\n",
    "mae = tf.reduce_mean(tf.abs(error))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "init = tf.global_variables_initializer()\n",
    "saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index 2731 is out of bounds for axis 1 with size 484",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-46-e1c6cda9e7a3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m             \u001b[0mbatch_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrand_idx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_i\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_i\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m             \u001b[0mX_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mseq_pad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data_arr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbatch_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_in\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseq_len\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m             \u001b[0my_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbatch_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m             \u001b[0mlen_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mseq_lens_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbatch_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m             loss_val, _ = sess.run(\n",
      "\u001b[0;31mIndexError\u001b[0m: index 2731 is out of bounds for axis 1 with size 484"
     ]
    }
   ],
   "source": [
    "n_samples = train_data_arr.shape[0]\n",
    "n_epochs = 5\n",
    "batch_size = len(train_data_arr) / 25\n",
    "#printbatch_size\n",
    "\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    for epoch in range(n_epochs):\n",
    "        rand_idx = np.random.permutation(np.arange(n_samples))\n",
    "        for batch_i in range(int(n_samples // batch_size)):\n",
    "            batch_idx = rand_idx[int(batch_i*batch_size):int((batch_i+1)*batch_size)]\n",
    "            X_batch = seq_pad(train_data_arr[batch_idx], n_in, seq_len)\n",
    "            y_batch = y_train[batch_idx]\n",
    "            len_batch = seq_lens_train[batch_idx]\n",
    "            loss_val, _ = sess.run(\n",
    "                [loss, training_op],\n",
    "                feed_dict={X: X_batch, seq_length: len_batch, y: y_batch})\n",
    "        mae_train = mae.eval(feed_dict={X: X_batch, seq_length: len_batch, y: y_batch})\n",
    "        mae_test = mae.eval(feed_dict={X: test_pad, seq_length: seq_lens_test, y: y_test})\n",
    "        print(\"{:4d}  Train loss: {:.4f}, Train MAE: {:.2f}  Test MAE: {:.2f}\".format(\n",
    "            epoch, loss_val, mae_train, mae_test))\n",
    "        saver.save(sess, \"my_reber_classifier\")\n",
    "        final_pred = y_pred.eval({X: test_pad, seq_length: seq_lens_test, y: y_test})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
